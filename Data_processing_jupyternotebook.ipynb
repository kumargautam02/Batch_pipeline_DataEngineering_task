{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8oJZsHY5lG6D"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-27 10:56:33,366 - Data_Processing Script started\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import zipfile\n",
        "import pyspark\n",
        "import logging\n",
        "import pandas as pd\n",
        "from database_script import get_connection\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "from sqlalchemy.exc import SQLAlchemyError\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "# from selenium import webdriver\n",
        "# from selenium.webdriver import chrome\n",
        "# from selenium.webdriver.common.by import By\n",
        "# from selenium.webdriver.chrome.service import Service\n",
        "# from webdriver_manager.chrome import ChromeDriverManager\n",
        "# from selenium.webdriver.common.keys import Keys\n",
        "# from selenium.webdriver.chrome.options import Options\n",
        "from data_ingestion_script import *\n",
        "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
        "logger = logging.getLogger('Data_Processing')\n",
        "logger.info('Data_Processing Script started')\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# logger.info(\"Running the requirements.txt file\")\n",
        "# !pip install -r requirements.txt\n",
        "# logger.info(\"requirements.txt runned successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-27 11:03:55,960 - ====== WebDriver manager ======\n",
            "2024-02-27 11:03:57,041 - Get LATEST chromedriver version for google-chrome\n",
            "2024-02-27 11:03:57,398 - Get LATEST chromedriver version for google-chrome\n",
            "2024-02-27 11:03:57,619 - Driver [C:\\Users\\Admin\\.wdm\\drivers\\chromedriver\\win64\\122.0.6261.69\\chromedriver-win32/chromedriver.exe] found in cache\n",
            "2024-02-27 11:04:15,044 - Download of Male_Dataset Started\n",
            "2024-02-27 11:04:17,337 - Download of Female_Dataset Started\n",
            "2024-02-27 11:04:19,364 - Ingestion of Data Completed successfully\n",
            "2024-02-27 11:04:19,364 - LANDING PATH IS THERE\n",
            "2024-02-27 11:04:19,364 - DOWNLOAD PATH IS THERE\n",
            "2024-02-27 11:04:19,753 - Data Loaded to Download path Successfully\n",
            "2024-02-27 11:04:19,753 - Started Extraction of file odis_female_json.zip\n",
            "2024-02-27 11:04:20,654 - Started Extraction of file odis_male_json.zip\n",
            "2024-02-27 11:04:25,330 - Data Extraction Completed Successfully\n"
          ]
        }
      ],
      "source": [
        "def start_ingesting_data(origin, target_directory):\n",
        "    try:\n",
        "        # Data Ingestion  to correct path\n",
        "        origin = origin\n",
        "        target_directory = target_directory\n",
        "        download_required_files(logger)\n",
        "        logger.info(\"Ingestion of Data Completed successfully\")\n",
        "\n",
        "        file_in_origin = os.listdir(origin)\n",
        "        \n",
        "        while (\"odis_female_json.zip\" not in file_in_origin) and (\"odis_male_json.zip\" not in file_in_origin):\n",
        "            file_in_origin = os.listdir(origin)\n",
        "            if (\"odis_female_json.zip\" in file_in_origin) and (\"odis_male_json.zip\" in file_in_origin):\n",
        "                logger.info(\"waiting for file to get downloaded\")\n",
        "                break\n",
        "        if ('LANDING' in os.listdir(f'{target_directory}')) and ('DOWNLOAD_PATH' in os.listdir(f'{target_directory}')):\n",
        "            logger.info(\"LANDING PATH IS THERE\")\n",
        "            logger.info(\"DOWNLOAD PATH IS THERE\")\n",
        "        else :\n",
        "            os.makedirs(f'{target_directory}LANDING')\n",
        "            logger.info(\"LANDING path created successfully\")\n",
        "            os.makedirs(f'{target_directory}DOWNLOAD_PATH')\n",
        "            logger.info(\"DOWNLOAD_PATH created created successfully\")\n",
        "\n",
        "        files_in_target_directory = os.listdir(target_directory+'DOWNLOAD_PATH')\n",
        "        needed_files = ['odis_female_json.zip', \"odis_male_json.zip\"]\n",
        "        file_in_origin = os.listdir(origin)\n",
        "        for file in file_in_origin:\n",
        "            if (file.startswith(\"odis_female_json\") or file.startswith(\"odis_male_json\")) and (('odis_female_json.json' not in files_in_target_directory) and ('odis_male_json.json' not in files_in_target_directory)):\n",
        "                shutil.copy(origin+file, target_directory+'DOWNLOAD_PATH')\n",
        "        logger.info(\"Data Loaded to Download path Successfully\")\n",
        "\n",
        "        #extracting all the files in landing folder\n",
        "        for file_name in needed_files:\n",
        "            if (file_name == \"odis_female_json.zip\") or (file_name == \"odis_male_json.zip\"):\n",
        "              logger.info(f\"Started Extraction of file {file_name}\")\n",
        "              with zipfile.ZipFile(f'{target_directory}/DOWNLOAD_PATH/{file_name}') as f:\n",
        "                      # f.extractall()/\n",
        "                      f.extractall(f'{target_directory}LANDING/')\n",
        "        logger.info(\"Data Extraction Completed Successfully\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        logging.error(\"Exception occurred\", exc_info=True)\n",
        "\n",
        "origin = 'C:/Users/Admin/Downloads/'\n",
        "target_directory = 'C:/Users/Admin/Downloads/procesing/Batch_pipeline_DataEngineering_task/'\n",
        "start_ingesting_data(origin, target_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K6COIFEtYaqB"
      },
      "outputs": [],
      "source": [
        "#Necessay Function\n",
        "def get_batter_bowler_striker(column, column_need):\n",
        "  try:\n",
        "    if column_need.strip() == 'batter':\n",
        "      return column['batter']\n",
        " \n",
        "    elif column_need.strip() == 'bowler':\n",
        "      return column['bowler']\n",
        "\n",
        "    elif column_need.strip() == 'non_striker':\n",
        "      return column['non_striker']\n",
        "  except Exception as e:\n",
        "    logging.error(\"Exception occurred\", exc_info=True)\n",
        "\n",
        "\n",
        "\n",
        "#Necessay Function\n",
        "def get_run_ball_by_ball(column):\n",
        "  try:\n",
        "\n",
        "    runs_list = [-1]*3\n",
        "    for scores in column.keys():\n",
        "      if scores == 'runs':\n",
        "        return column[scores]\n",
        "      \n",
        "  except Exception as e:\n",
        "    logging.error(\"Exception occurred\", exc_info=True)\n",
        "\n",
        "\n",
        "def get_info_and_meta_data(all_information):\n",
        "  try:\n",
        "      for data in all_information.keys():\n",
        "        if data == 'meta':\n",
        "          meta_information = all_information['meta']\n",
        "        elif data == 'info':\n",
        "          info_information = all_information[\"info\"]\n",
        "      return meta_information, info_information\n",
        "  except Exception as e:\n",
        "    logging.error(\"Exception occurred\", exc_info=True)\n",
        "\n",
        "def get_necessary_information(data):\n",
        "  try:\n",
        "      date = data['dates'][0]\n",
        "\n",
        "      if \"city\" in data.keys():\n",
        "        city = data['city']\n",
        "      else:\n",
        "        city = \"NULL\"\n",
        "      if 'event' in data.keys():\n",
        "        event_name = data['event']['name']\n",
        "        if 'match_number' in data['event'].keys():\n",
        "          match_number = data['event']['match_number']\n",
        "        else:\n",
        "          match_number = \"NULL\"\n",
        "      else:\n",
        "        event_name = \"NULL\"\n",
        "        match_number = \"NULL\"\n",
        "\n",
        "      gender = data['gender']\n",
        "\n",
        "      if \"winner\" in data['outcome'].keys():\n",
        "\n",
        "        winner_team = data['outcome']['winner']\n",
        "      elif 'result' in data['outcome'].keys():\n",
        "\n",
        "        winner_team = data['outcome']['result']\n",
        "\n",
        "      if \"winner\" in data['outcome'].keys():\n",
        "        if 'wickets' in data['outcome']['by'].keys():\n",
        "          winned_by = f\"{data['outcome']['by']['wickets']} wickets\"\n",
        "        elif 'runs' in data['outcome']['by'].keys():\n",
        "          winned_by = f\"{data['outcome']['by']['runs']} runs\"\n",
        "      else:\n",
        "        winned_by = \"NULL\"\n",
        "      team_1 = data['teams'][0]\n",
        "      team_2 = data['teams'][1]\n",
        "      return date, city, event_name, match_number, gender, winner_team, winned_by, team_1, team_2\n",
        "  except Exception as e:\n",
        "    logging.error(\"Exception occurred\", exc_info=True)\n",
        "\n",
        "#UDF created to get the run scored ball-by-ball\n",
        "get_run_ball_by_ball_udf =  udf(lambda column: get_run_ball_by_ball(column), StringType())\n",
        "#UDF created to get the batter name, striker name, bowler name\n",
        "get_batter_bowler_striker_udf =  udf(lambda column, column_need: get_batter_bowler_striker(column, column_need), StringType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[overs: string, FIRST_TEAM: string, SECOND_TEAM: string, EVENT_NAME: string, MATCH_DATE: string, MATCH_CITY: string, MATCH_NUMBER: string, GENDER: string, WINNER_TEAM: string, WINNED_BY: string, BATTER: string, BOWLER: string, NON_STRIKER: string, BATTER_SCORED_RUNS_PER_BALL: string, TOTAL_RUNS_PER_BALL: string, EXTRAS_EARNED_PER_BALL: string]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create an empty schema\n",
        "\n",
        "# columns = StructType([])\n",
        "list_of_cols=[StructField(\"overs\",StringType(),True),\n",
        "             StructField(\"FIRST_TEAM\",StringType(),True),\n",
        "             StructField(\"SECOND_TEAM\",StringType(),True),\n",
        "             StructField(\"EVENT_NAME\",StringType(),True),\n",
        "             StructField(\"MATCH_DATE\",StringType(),True),\n",
        "             StructField(\"MATCH_CITY\",StringType(),True),\n",
        "             StructField(\"MATCH_NUMBER\",StringType(),True),\n",
        "             StructField(\"GENDER\",StringType(),True),\n",
        "             StructField(\"WINNER_TEAM\",StringType(),True),\n",
        "             StructField(\"WINNED_BY\",StringType(),True),\n",
        "             StructField(\"BATTER\",StringType(),True),\n",
        "             StructField(\"BOWLER\",StringType(),True),\n",
        "             StructField(\"NON_STRIKER\",StringType(),True),\n",
        "             StructField(\"BATTER_SCORED_RUNS_PER_BALL\",StringType(),True),\n",
        "             StructField(\"TOTAL_RUNS_PER_BALL\",StringType(),True),\n",
        "             StructField(\"EXTRAS_EARNED_PER_BALL\",StringType(),True)]\n",
        "schema=StructType(list_of_cols)\n",
        "# Create an empty dataframe with empty schema\n",
        "df = spark.createDataFrame(data = [],\n",
        "                           schema = schema)\n",
        "df.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8X_QVfXEAO8",
        "outputId": "d17df61c-d119-4cd8-97f2-abaf331a14a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-27 11:03:48,124 - Exception occurred\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9888\\2622827490.py\", line 2, in <module>\n",
            "    path = target_directory+'LANDING/'\n",
            "NameError: name 'target_directory' is not defined\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  path = target_directory+'LANDING/'\n",
        "  all_the_files = os.listdir(path)\n",
        "  # print(all_the_files)\n",
        "  necessary_columns = []\n",
        "  for i in all_the_files:\n",
        "    # print(f\"/female_dataset/{i}\")\n",
        "    print(i)\n",
        "    if i.endswith(\".json\"):\n",
        "      with open(f\"{path}/{i}\",\"r\") as file_obj:\n",
        "        file_content = file_obj.read()\n",
        "        # print(file_content)\n",
        "        details = json.loads(file_content)\n",
        "        meta_information, info_information = get_info_and_meta_data(details)\n",
        "        date, city, event_name, match_number, gender, winner_team, winned_by, team_1, team_2 = get_necessary_information(info_information)\n",
        "        necessary_columns = []\n",
        "        temp_dict = {}\n",
        "        for i in range(len(details['innings'][0]['overs'])):\n",
        "          temp_dict['overs'] = i\n",
        "          temp_dict['balls_per_over'] = details['innings'][0]['overs'][i]['deliveries']\n",
        "          # print(student_details['innings'][0]['overs'][i]['deliveries'])\n",
        "          necessary_columns.append(temp_dict)\n",
        "          temp_dict = {}\n",
        "        dataframe = spark.createDataFrame(necessary_columns)\n",
        "        # dataframe.show(1000, False)\n",
        "        dataframe = dataframe.select(\"overs\", posexplode_outer(dataframe.balls_per_over))\n",
        "\n",
        "        dataframe_new = dataframe.withColumn(\"BATTER\", get_batter_bowler_striker_udf(col(\"col\"), lit(\"batter\")))\n",
        "        dataframe_new = dataframe_new.withColumn(\"BOWLER\", get_batter_bowler_striker_udf(col(\"col\"), lit(\"bowler\")))\n",
        "        dataframe_new = dataframe_new.withColumn(\"NON_STRIKER\", get_batter_bowler_striker_udf(col(\"col\"), lit(\"non_striker\")))\n",
        "        dataframe_new = dataframe_new.withColumn(\"runs_scored_per_ball\", get_run_ball_by_ball_udf(col(\"col\")))\n",
        "        dataframe_new = dataframe_new.select('*', lit(date).alias(\"MATCH_DATE\"), lit(city).alias(\"MATCH_CITY\"),\\\n",
        "                                            lit(event_name).alias(\"EVENT_NAME\"),lit(match_number).alias(\"MATCH_NUMBER\"),lit(gender).alias(\"GENDER\"),\\\n",
        "                                            lit(winner_team).alias(\"WINNER_TEAM\"),lit(winned_by).alias(\"WINNED_BY\"),lit(team_1).alias(\"FIRST_TEAM\"),lit(team_2).alias(\"SECOND_TEAM\"))\n",
        "\n",
        "        dataframe_new = dataframe_new.withColumn(\"runs_scored_per_ball\", regexp_replace(col(\"runs_scored_per_ball\"), \"(\\{extras=)|(total=)|(batter=)|(\\})\", \"\")).withColumn(\"EXTRAS_EARNED_PER_BALL\", trim(split(col(\"runs_scored_per_ball\"), ',').getItem(0))).withColumn(\"TOTAL_RUNS_PER_BALL\", trim(split(col(\"runs_scored_per_ball\"), ',').getItem(1))).withColumn(\"BATTER_SCORED_RUNS_PER_BALL\", trim(split(col(\"runs_scored_per_ball\"), ',').getItem(2)))\n",
        "        dataframe_new = dataframe_new.select('overs','FIRST_TEAM', 'SECOND_TEAM','EVENT_NAME','MATCH_DATE','MATCH_CITY','MATCH_NUMBER','GENDER','WINNER_TEAM','WINNED_BY','BATTER','BOWLER','NON_STRIKER','BATTER_SCORED_RUNS_PER_BALL','TOTAL_RUNS_PER_BALL', 'EXTRAS_EARNED_PER_BALL')\n",
        "        # dataframe_new.write.parquet(\"/output_folder/\")\\\n",
        "        # dataframe_new.write.mode(\"append\").format(\"parquet\").save(\"/output_folder/\")\n",
        "        # df = df.unionByName(dataframe_new)\n",
        "        # dataframe_new.show(10, False)\n",
        "        dataframe_new = dataframe_new.toPandas()\n",
        "        # dataframe_new.to_sql(con = my_conn, name = 'male', if_exists='replace')\n",
        "        # dataframe_new.show(10, Fals\n",
        "        # result = my_conn.execute(text(\"select * from male where WINNED_BY NOT like '%runs%'\"))\n",
        "        # print(result.all())\n",
        "        print(i)\n",
        "        print(f\"{path}/{i}\")\n",
        "\n",
        "except Exception as e:\n",
        "  logging.error(\"Exception occurred\", exc_info=True)\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "README.txt\n"
          ]
        }
      ],
      "source": [
        "print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_new = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_new' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_new\u001b[49m\u001b[38;5;241m.\u001b[39mcount()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'df_new' is not defined"
          ]
        }
      ],
      "source": [
        "df_new.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
